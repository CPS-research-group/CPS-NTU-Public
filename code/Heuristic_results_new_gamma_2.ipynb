{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c6a559c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f67b54",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5fcb39a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_pickle(filename):\n",
    "    infile = open(filename,'rb')\n",
    "    dict_data = pickle.load(infile)\n",
    "    infile.close()\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bf2f158",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def write_pickle(dict_data, filename):\n",
    "    pickling_on = open(filename+'.pickle',\"wb\")\n",
    "    pickle.dump(dict_data, pickling_on)\n",
    "    pickling_on.close()\n",
    "    print('saved file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849ef76c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tasksets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4577146c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_data keys:  dict_keys(['tasksets', 'results', 'other_test_data'])\n",
      "\n",
      "num of tasksets keys:  12000\n",
      "\n",
      "num of results keys:  12000\n",
      "\n",
      "results[0] keys:  dict_keys(['percent_comp_int', 'percent_bdwth_int', 'num_tasks'])\n",
      "\n",
      "other_test_data keys:  dict_keys(['V_k', 'U_j', 'C_k', 'B_j', 'delta_jk', 'alpha', 'beta', 'cloud_server', 'edge_server', 'unit_b', 'unit_c'])\n"
     ]
    }
   ],
   "source": [
    "# CAN CHANGE INPUT FILE NAME HERE\n",
    "\n",
    "dict_data = read_pickle('data/experiment_data.pickle')\n",
    "\n",
    "print('dict_data keys: ', dict_data.keys())\n",
    "print()\n",
    "print('num of tasksets keys: ', len(dict_data['tasksets'].keys()))\n",
    "print()\n",
    "print('num of results keys: ', len(dict_data['results'].keys()))\n",
    "print()\n",
    "print('results[0] keys: ', dict_data['results'][0].keys())\n",
    "print()\n",
    "print('other_test_data keys: ', dict_data['other_test_data'].keys())\n",
    "\n",
    "tasksets = dict_data['tasksets']\n",
    "results = dict_data['results']\n",
    "other_test_data = dict_data['other_test_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b0cfe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Heuristic - New Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88c7136b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_split_values(tasks, theta_i, S_i, tau_i, N_E_i, edge_server, cloud_server, C_k, B_j):\n",
    "    \n",
    "    gamma_ijk = {}\n",
    "    \n",
    "    N_I_e = {}\n",
    "    for edge in edge_server:\n",
    "        N_I_e[edge] = []\n",
    "\n",
    "        for task in N_E_i:\n",
    "            if edge in N_E_i[task]:\n",
    "                N_I_e[edge].append(task)\n",
    "    \n",
    "    for task in tasks:\n",
    "        gamma_ijk[task] = {}\n",
    "        \n",
    "        for edge in N_E_i[task]:\n",
    "            gamma_ijk[task][edge] = {}\n",
    "    \n",
    "            for proc_server in edge_server+cloud_server:\n",
    "            \n",
    "                numer = (S_i[task] / tau_i[task]) / B_j[edge]\n",
    "                denom = (theta_i[task] / tau_i[task]) / C_k[proc_server]\n",
    "                \n",
    "                gamma_ijk[task][edge][proc_server] = numer / (numer + denom)\n",
    "                \n",
    "                \n",
    "    return gamma_ijk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac58e874",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_utilization_values(tasks, theta_i, S_i, tau_i, gamma_ijk, N_E_i, delta_jk):\n",
    "    \n",
    "    utilizations = {}\n",
    "    \n",
    "    for task in tasks:\n",
    "        utilizations[task] = {}\n",
    "        for edge in N_E_i[task]:\n",
    "            for jk in delta_jk:\n",
    "                if edge == jk[0]:\n",
    "                    time1 = (tau_i[task] - 2*delta_jk[jk]) * gamma_ijk[task][edge][jk[1]]\n",
    "                    time2 = (tau_i[task] - 2*delta_jk[jk]) * (1-gamma_ijk[task][edge][jk[1]])\n",
    "                    \n",
    "                    # (bandwidth util, compute util)\n",
    "                    utilizations[task][jk] = ((S_i[task]/time1), (theta_i[task]/time2))\n",
    "    \n",
    "    return utilizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99815705",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_priorities(utilizations, G_i, C_k, B_j):\n",
    "    p_ijk = {}\n",
    "    \n",
    "    for task in utilizations.keys():\n",
    "        for jk in utilizations[task].keys():\n",
    "            \n",
    "            p_ijk[(task, jk[0], jk[1])] = G_i[task]/(utilizations[task][jk][0]/B_j[jk[0]] * utilizations[task][jk][1]/C_k[jk[1]])\n",
    "            \n",
    "    return p_ijk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640d45d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def heuristic_no_update(tasks, theta_i, S_i, tau_i, G_i, N_E_i, C_k, B_j, delta_jk, edge_server, cloud_server):\n",
    "    '''\n",
    "    IMPORTANT: remember to input copy of B_j and C_k since they will be changed \n",
    "    '''\n",
    "        \n",
    "    total_profit = 0\n",
    "    num_tasks_offloaded = 0\n",
    "    \n",
    "    gamma_ijk = calculate_split_values(tasks, theta_i, S_i, tau_i, N_E_i, edge_server, cloud_server, C_k, B_j)\n",
    "    utilizations = calculate_utilization_values(tasks, theta_i, S_i, tau_i, gamma_ijk, N_E_i, delta_jk)\n",
    "    p_ijk = calculate_priorities(utilizations, G_i, C_k, B_j)\n",
    "    \n",
    "    num_runs = 0\n",
    "    \n",
    "    while p_ijk != {}:\n",
    "        \n",
    "        max_key = max(p_ijk, key= lambda x:p_ijk[x])\n",
    "        \n",
    "        if utilizations[max_key[0]][(max_key[1], max_key[2])][0] <= B_j[max_key[1]] and utilizations[max_key[0]][(max_key[1], max_key[2])][1] <= C_k[max_key[2]]:\n",
    "            \n",
    "            B_j[max_key[1]] -= utilizations[max_key[0]][(max_key[1], max_key[2])][0]\n",
    "            C_k[max_key[2]] -= utilizations[max_key[0]][(max_key[1], max_key[2])][1]\n",
    "\n",
    "            total_profit += G_i[max_key[0]]\n",
    "            num_tasks_offloaded += 1\n",
    "            \n",
    "            keys_to_pop = []\n",
    "            for key in p_ijk.keys():\n",
    "                if key[0] == max_key[0]:\n",
    "                    keys_to_pop.append(key)\n",
    "            for key in keys_to_pop:\n",
    "                p_ijk.pop(key)\n",
    "        \n",
    "        else:\n",
    "            p_ijk.pop(max_key)\n",
    "            \n",
    "    \n",
    "    return total_profit, num_tasks_offloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5f99833",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def check_runtime_and_profit_heusristic_no_update(tasksets, other_test_data, taskset_ID):\n",
    "    \n",
    "    taskset = tasksets[taskset_ID]\n",
    "    \n",
    "    tasks = taskset['tasks']\n",
    "    G_i = taskset['G_i']\n",
    "    tau_i = taskset['tau_i']\n",
    "    theta_i = taskset['theta_i']\n",
    "    S_i = taskset['S_i']\n",
    "    N_E_i = taskset['N_E_i']\n",
    "    \n",
    "    V_k = other_test_data['V_k']\n",
    "    U_j = other_test_data['U_j']\n",
    "    C_k = other_test_data['C_k']\n",
    "    B_j = other_test_data['B_j']\n",
    "    delta_jk = other_test_data['delta_jk']\n",
    "    alpha = other_test_data['alpha']\n",
    "    beta = other_test_data['beta']\n",
    "    cloud_server = other_test_data['cloud_server']\n",
    "    edge_server = other_test_data['edge_server']\n",
    "    b_unit = other_test_data['unit_b']\n",
    "    c_unit = other_test_data['unit_c']\n",
    "    \n",
    "#     tasks_copy = tasks.copy()\n",
    "#     N_E_i_copy = copy.deepcopy(N_E_i)\n",
    "    B_j_copy = B_j.copy()\n",
    "    C_k_copy = C_k.copy()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    total_profit, num_tasks_offloaded= heuristic_no_update(tasks, theta_i, S_i, tau_i, G_i, N_E_i, C_k_copy, B_j_copy, delta_jk, edge_server, cloud_server)\n",
    "    total_time_execution = time.time() - start_time\n",
    "    \n",
    "    return total_profit, num_tasks_offloaded, total_time_execution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa369f7c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3df544cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "#     ******************************\n",
    "#           CHANGE INPUT FILE\n",
    "#     ******************************\n",
    "    \n",
    "    dict_data = read_pickle('data/experiment_data.pickle')\n",
    "    tasksets = dict_data['tasksets']\n",
    "    results = dict_data['results']\n",
    "    other_test_data = dict_data['other_test_data']\n",
    "    print('Information from main()')\n",
    "    print('-----------------------------------------------')\n",
    "    print('Number of tasksets: ', len(tasksets.keys()))\n",
    "    \n",
    "    heuristic_profit, heuristic_runtime, heuristic_num_offloaded = {}, {}, {}\n",
    "    \n",
    "    \n",
    "    number_evaluated = 0\n",
    "    \n",
    "    for ID in tasksets.keys():\n",
    "        \n",
    "        profit, num_tasks_offloaded, total_time_execution = check_runtime_and_profit_heusristic_no_update(tasksets, other_test_data, ID)\n",
    "\n",
    "        heuristic_profit[ID] = profit\n",
    "        heuristic_num_offloaded[ID] = num_tasks_offloaded\n",
    "        heuristic_runtime[ID] = total_time_execution\n",
    "\n",
    "        number_evaluated += 1\n",
    "        if(number_evaluated%1000 == 0):\n",
    "            print('number of tasksets evaluated: ', number_evaluated)\n",
    "            \n",
    "    print('-----------------------------------------------')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    dict_data['heuristic_profit'] = heuristic_profit\n",
    "    dict_data['heuristic_num_offloaded'] = heuristic_num_offloaded\n",
    "    dict_data['heuristic_runtime'] = heuristic_runtime\n",
    "    \n",
    "#     ****************************************\n",
    "#             CHANGE OUTPUT FILE NAME \n",
    "#     ****************************************\n",
    "\n",
    "    write_pickle(dict_data, 'data/heuritic_results_new_gamma_2_full')\n",
    "    \n",
    "    \n",
    "    \n",
    "#     ****************************************\n",
    "#                 CHANGE SPLITTING\n",
    "#     ****************************************\n",
    "    sizes = [40, 60, 80, 100, 120]\n",
    "    split_data = {}\n",
    "\n",
    "    for size in sizes:\n",
    "        split_data[size] = {'tasksets':{}, 'results':{},'heuristic_profit':{},'heuristic_runtime':{}, 'heuristic_num_offloaded':{}}\n",
    "        split_data[size]['other_test_data'] = dict_data['other_test_data']\n",
    "    \n",
    "    for ID in dict_data['tasksets'].keys():\n",
    "        num_tasks = len(dict_data['tasksets'][ID]['tasks'])\n",
    "        if num_tasks in sizes:\n",
    "            split_data[num_tasks]['tasksets'][ID] = dict_data['tasksets'][ID]\n",
    "            split_data[num_tasks]['results'][ID] = dict_data['results'][ID]\n",
    "            split_data[num_tasks]['heuristic_profit'][ID] = dict_data['heuristic_profit'][ID]\n",
    "            split_data[num_tasks]['heuristic_runtime'][ID] = dict_data['heuristic_runtime'][ID]\n",
    "            split_data[num_tasks]['heuristic_num_offloaded'][ID] = dict_data['heuristic_num_offloaded'][ID]\n",
    "        else:\n",
    "            print(\"Wrong instance size: [ID, size] = [\", ID, \", \", num_tasks, \"]\")\n",
    "            break\n",
    "\n",
    "    print()\n",
    "    for size in sizes:\n",
    "        print('Number of tasksets with ', size, ' tasks: ', len(split_data[size]['tasksets'].keys()))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "#     ****************************************\n",
    "#             CHANGE OUTPUT FILES' NAMES\n",
    "#     ****************************************\n",
    "    for size in sizes:\n",
    "        path = \"data/heuristic_results_size_\" + str(size)\n",
    "        write_pickle(split_data[size], path)\n",
    "\n",
    "    return split_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9214af42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information from main()\n",
      "-----------------------------------------------\n",
      "Number of tasksets:  12000\n",
      "number of tasksets evaluated:  1000\n",
      "number of tasksets evaluated:  2000\n",
      "number of tasksets evaluated:  3000\n",
      "number of tasksets evaluated:  4000\n",
      "number of tasksets evaluated:  5000\n",
      "number of tasksets evaluated:  6000\n",
      "number of tasksets evaluated:  7000\n",
      "number of tasksets evaluated:  8000\n",
      "number of tasksets evaluated:  9000\n",
      "number of tasksets evaluated:  10000\n",
      "number of tasksets evaluated:  11000\n",
      "number of tasksets evaluated:  12000\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "saved file\n",
      "\n",
      "Number of tasksets with  40  tasks:  2400\n",
      "Number of tasksets with  60  tasks:  2400\n",
      "Number of tasksets with  80  tasks:  2400\n",
      "Number of tasksets with  100  tasks:  2400\n",
      "Number of tasksets with  120  tasks:  2400\n",
      "\n",
      "saved file\n",
      "saved file\n",
      "saved file\n",
      "saved file\n",
      "saved file\n"
     ]
    }
   ],
   "source": [
    "start_time_overall = time.time()\n",
    "split_data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a08a19a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40  mean time limit:  0.023715402881304422\n",
      "40  max run time:  [0.06804275512695312, 0.06694149971008301, 0.06634283065795898]\n",
      "60  mean time limit:  0.03751540382703145\n",
      "60  max run time:  [0.10289740562438965, 0.09978389739990234, 0.0997157096862793]\n",
      "80  mean time limit:  0.052524661322434746\n",
      "80  max run time:  [0.1327834129333496, 0.12763047218322754, 0.12621641159057617]\n",
      "100  mean time limit:  0.0711213626464208\n",
      "100  max run time:  [0.34988903999328613, 0.159027099609375, 0.15554022789001465]\n",
      "120  mean time limit:  0.09438423921664556\n",
      "120  max run time:  [0.23330974578857422, 0.22350215911865234, 0.21761274337768555]\n",
      "\n",
      "\n",
      "total time taken :  675.810308933258\n"
     ]
    }
   ],
   "source": [
    "sizes = [40, 60, 80, 100, 120]\n",
    "for size in sizes:\n",
    "    subset_heuristic_run_time = list(split_data[size]['heuristic_runtime'].values())\n",
    "    print(size, ' mean time limit: ', sum(subset_heuristic_run_time)/len(subset_heuristic_run_time))\n",
    "    subset_heuristic_run_time.sort(reverse=True)\n",
    "    print(size, \" max run time: \", subset_heuristic_run_time[:3])\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('total time taken : ', time.time() - start_time_overall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}